{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80f8c58",
   "metadata": {},
   "source": [
    "#  Data Model for Sales (salesadb) \n",
    "\n",
    "## Overview\n",
    "This notebook creates Sales domain tables that integrate with shared data.\n",
    "\n",
    "## Schema Structure\n",
    "- **Sales Domain**: 3 tables (Order, OrderLine, OrderPayment)\n",
    "- **Integration**: Links to shared Customer, Product, Location tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3562f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks Notebook: Sales Domain Tables Creation\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Widgets (so you can configure from UI/job)\n",
    "dbutils.widgets.text(\"catalog_name\", \"maag_adb2\")\n",
    "dbutils.widgets.text(\"schema_name\", \"sales\")\n",
    "\n",
    "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema_name\")\n",
    "\n",
    "print(f\"ðŸ“‚ Using catalog: {CATALOG_NAME}, schema: {SCHEMA_NAME}\")\n",
    "\n",
    "# Create schema if not exists\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "\n",
    "################################################################################################\n",
    "# SALES DOMAIN TABLES - Databricks\n",
    "################################################################################################\n",
    "\n",
    "# 1. Create Order table\n",
    "TABLE_NAME = \"Order\"\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}.{TABLE_NAME} (\n",
    "    OrderId STRING,         -- Unique identifer like UUID\n",
    "    SalesChannelId STRING,  -- Values: Databricks, Fabric \n",
    "    OrderNumber STRING,     -- Customer-facing order number\n",
    "    CustomerId STRING,      -- FK to Customer \n",
    "    CustomerAccountId STRING,\n",
    "    OrderDate DATE,\n",
    "    OrderStatus STRING,\n",
    "    SubTotal DECIMAL(18,2),\n",
    "    TaxAmount DECIMAL(18,2),\n",
    "    OrderTotal DECIMAL(18,2),\n",
    "    PaymentMethod STRING,\n",
    "    IsoCurrencyCode STRING,\n",
    "    CreatedBy STRING \n",
    ")\n",
    "USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(create_table_sql)\n",
    "print(f\"âœ… {SCHEMA_NAME}.{TABLE_NAME} table created!\")\n",
    "\n",
    "# 2. Create OrderLine table\n",
    "TABLE_NAME = \"OrderLine\"\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}.{TABLE_NAME} (\n",
    "    OrderId STRING,       -- FK to Order table\n",
    "    OrderLineNumber INT,  -- incremental number for each line item, like 1, 2, 3.\n",
    "    ProductId STRING,     -- FK to Product\n",
    "    ProductName STRING,\n",
    "    Quantity DECIMAL(18,2),\n",
    "    UnitPrice DECIMAL(18,2),\n",
    "    LineTotal DECIMAL(18,2),\n",
    "    DiscountAmount DECIMAL(18,2), \n",
    "    TaxAmount DECIMAL(18,2)\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(create_table_sql)\n",
    "print(f\"âœ… {SCHEMA_NAME}.{TABLE_NAME} table created!\")\n",
    "\n",
    "# 3. Create OrderPayment table\n",
    "TABLE_NAME = \"OrderPayment\"\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}.{TABLE_NAME} (\n",
    "    OrderId STRING,          -- FK to Order table\n",
    "    PaymentMethod STRING,    -- VISA, MC, Discover, PayPal.\n",
    "    TransactionId STRING     -- UUID for Payment Transaction\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(create_table_sql)\n",
    "print(f\"âœ… {SCHEMA_NAME}.{TABLE_NAME} table created!\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ TABLES CREATION COMPLETE in {CATALOG_NAME}.{SCHEMA_NAME}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
