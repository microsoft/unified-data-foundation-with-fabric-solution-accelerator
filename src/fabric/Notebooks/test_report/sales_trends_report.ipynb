{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cf161a",
   "metadata": {},
   "source": [
    "# Sales Trends by Year\n",
    "\n",
    "This notebook calculates total sales for each year (2019-2024) using the Order table and visualizes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983c391",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, sum as spark_sum, year\n",
    "\n",
    "# Configuration\n",
    "WORKSPACE_NAME = \"Fabric_MAAG\"\n",
    "SOURCE_LAKEHOUSE_NAME = \"maag_silver\"\n",
    "SOURCE_SCHEMA = \"salesadb\"\n",
    "SOURCE_TABLE = \"order\"\n",
    "\n",
    "SOURCE_TABLE_PATH = f\"abfss://{WORKSPACE_NAME}@onelake.dfs.fabric.microsoft.com/{SOURCE_LAKEHOUSE_NAME}.Lakehouse/Tables/{SOURCE_SCHEMA}/{SOURCE_TABLE}\"\n",
    "\n",
    "# Read Order table from lakehouse\n",
    "df = spark.read.format(\"delta\").load(SOURCE_TABLE_PATH)\n",
    "\n",
    "# Extract year from OrderDate\n",
    "df = df.withColumn(\"Year\", year(col(\"OrderDate\")))\n",
    "\n",
    "# Aggregate total sales by year, exclude 2025\n",
    "sales_by_year = (\n",
    "    df.groupBy(\"Year\")\n",
    "      .agg(spark_sum(col(\"OrderTotal\")).alias(\"TotalSales\"))\n",
    "      .orderBy(\"Year\")\n",
    "      .filter(col(\"Year\") < 2025)\n",
    ")\n",
    "\n",
    "pdf = sales_by_year.toPandas()\n",
    "\n",
    "print(\"Total sales by year (excluding 2025):\")\n",
    "print(pdf)\n",
    "\n",
    "# Plot sales trends\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pdf[\"Year\"], pdf[\"TotalSales\"], marker='o')\n",
    "plt.title(\"Total Sales by Year (2019-2024)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Total Sales (Thousands)\")\n",
    "plt.grid(True)\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x/1000):,}K'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "1acd48dc-8b9d-4f55-ae21-a60a67b20bf4",
    "default_lakehouse_name": "MAAG_LH_Silver",
    "default_lakehouse_workspace_id": "e1e9b2bb-4338-4ab7-86fc-28098538ede0",
    "known_lakehouses": [
     {
      "id": "1acd48dc-8b9d-4f55-ae21-a60a67b20bf4"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
